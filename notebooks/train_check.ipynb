{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-21T13:47:32.674207Z",
     "start_time": "2024-01-21T13:47:28.067073Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchaudio.transforms as t"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T13:47:33.743415Z",
     "start_time": "2024-01-21T13:47:33.704259Z"
    }
   },
   "id": "fcd1498c4394fe32",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from src.acoustic_embedding_matching.networks.wavenet.modules import WaveNetBlock\n",
    "from src.acoustic_embedding_matching.networks.model import AcousticEmbeddingMatching\n",
    "from src.acoustic_embedding_matching.networks.embedding_network import EmbeddingNetwork"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:02:28.134468Z",
     "start_time": "2024-01-21T14:02:28.095069Z"
    }
   },
   "id": "1dfeef5a25ef8fd0",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([8, 16])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_net = EmbeddingNetwork(embedding_size=16, num_layers=5)\n",
    "to_spectrogram = t.Spectrogram(n_fft=1024, hop_length=512, win_length=1024)\n",
    "\n",
    "wav = torch.randn(8, 16_000 * 3)\n",
    "spec = to_spectrogram(wav)\n",
    "emb_net(spec).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T13:48:42.421367Z",
     "start_time": "2024-01-21T13:48:39.467008Z"
    }
   },
   "id": "cbedca485fecaf25",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "aem = AcousticEmbeddingMatching()\n",
    "source = torch.randn(8, 16_000 * 3)\n",
    "target = torch.randn(8, 16_000 * 3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:28:30.486457Z",
     "start_time": "2024-01-21T14:28:28.337614Z"
    }
   },
   "id": "44bb8c65568b8ec0",
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_embed: torch.Size([8, 16])\n",
      "target_embed: torch.Size([8, 16])\n",
      "Input shape to layer 0: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n",
      "Input shape to layer 1: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n",
      "Input shape to layer 2: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n",
      "Input shape to layer 3: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n",
      "Input shape to layer 4: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n",
      "Input shape to layer 5: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n",
      "Input shape to layer 6: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n",
      "Input shape to layer 7: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n",
      "Input shape to layer 8: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n",
      "Input shape to layer 9: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n",
      "Input shape to layer 0: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n",
      "Input shape to layer 1: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n",
      "Input shape to layer 2: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n",
      "Input shape to layer 3: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n",
      "Input shape to layer 4: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n",
      "Input shape to layer 5: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n",
      "Input shape to layer 6: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n",
      "Input shape to layer 7: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n",
      "Input shape to layer 8: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n",
      "Input shape to layer 9: torch.Size([8, 128, 48000]) | torch.Size([8, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[[-0.0952, -0.0961, -0.0953,  ..., -0.0938, -0.0943, -0.0914]],\n\n        [[-0.0972, -0.0981, -0.0971,  ..., -0.0964, -0.0969, -0.0936]],\n\n        [[-0.0973, -0.0980, -0.0965,  ..., -0.0946, -0.0952, -0.0922]],\n\n        ...,\n\n        [[-0.0958, -0.0969, -0.0960,  ..., -0.0954, -0.0957, -0.0928]],\n\n        [[-0.0945, -0.0954, -0.0943,  ..., -0.0942, -0.0949, -0.0917]],\n\n        [[-0.0947, -0.0953, -0.0941,  ..., -0.0931, -0.0938, -0.0908]]],\n       grad_fn=<ConvolutionBackward0>)"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aem(source, target)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:29:40.354594Z",
     "start_time": "2024-01-21T14:28:32.003429Z"
    }
   },
   "id": "6ae48bc22d56c2a3",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:02:29.869213Z",
     "start_time": "2024-01-21T14:02:29.829432Z"
    }
   },
   "id": "4317250f7fc3fef5",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "source = torch.randn(8, 128, 16_000 * 3)\n",
    "condition = torch.randn(8, 16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:03:08.621116Z",
     "start_time": "2024-01-21T14:03:07.927448Z"
    }
   },
   "id": "29a92f9af9f8ecd9",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: torch.Size([8, 128, 48000])\n",
      "condition.shape: torch.Size([8, 16, 1])\n",
      "x.shape: torch.Size([8, 128, 48000])\n",
      "condition.shape: torch.Size([8, 16, 1])\n"
     ]
    }
   ],
   "source": [
    "i = 8\n",
    "block = WaveNetBlock(128, 1, 16, 2 ** i)\n",
    "res, skip = block(source, condition)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:05:25.412253Z",
     "start_time": "2024-01-21T14:05:23.308795Z"
    }
   },
   "id": "cf0a21d1098e04c4",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([8, 128, 48000]), torch.Size([8, 48000]))"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape, skip.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:05:26.082082Z",
     "start_time": "2024-01-21T14:05:26.044642Z"
    }
   },
   "id": "ebd9764453fb181e",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "be6f789d8d9da8e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
